{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e09f356b-e7c2-482d-b46c-78c4e63dd72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRansformacion de imagenes (Segmentacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d303406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fdd604",
   "metadata": {},
   "source": [
    "# Segmentacion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d5f4fc2-5e1e-475c-9474-3d91092693ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Combinaciones (definidas completas)\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow.keras'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import time\n",
    "\n",
    "# Combinaciones (definidas completas)\n",
    "combinaciones_no_casco = [\n",
    "    ImageDataGenerator(horizontal_flip=True, shear_range=5),\n",
    "    ImageDataGenerator(rotation_range=10, brightness_range=(1.2, 1.5)),\n",
    "    ImageDataGenerator(rotation_range=15, zoom_range=[0.7, 1.4]),\n",
    "    #ImageDataGenerator(brightness_range=(0.5, 0.8), rotation_range=15),\n",
    "   # ImageDataGenerator(zoom_range=0.5),  # extra\n",
    "]\n",
    "\n",
    "combinaciones_casco = [\n",
    "    ImageDataGenerator(rotation_range=30, horizontal_flip=True),\n",
    "    ImageDataGenerator(rotation_range=10, brightness_range=(1.2, 1.5)),\n",
    "    ImageDataGenerator(brightness_range=(0.5, 0.8), rotation_range=15),\n",
    "    #ImageDataGenerator(rotation_range=15, vertical_flip=True),\n",
    "    ImageDataGenerator(width_shift_range=0.2, shear_range=5),\n",
    "    ImageDataGenerator(horizontal_flip=True, zoom_range=[0.7, 1.4]),\n",
    "]\n",
    "\n",
    "def cargar_imagenes_cv2(ruta_carpeta):\n",
    "    imagenes = []\n",
    "    archivos = os.listdir(ruta_carpeta)\n",
    "    for archivo in archivos:\n",
    "        img_path = os.path.join(ruta_carpeta, archivo)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        imagenes.append((img, archivo))\n",
    "    return imagenes\n",
    "\n",
    "def guardar_imagenes_aumentadas(imagenes, datagens, ruta_salida, n_transform):\n",
    "    os.makedirs(ruta_salida, exist_ok=True)\n",
    "    total_imagenes = len(imagenes) * (1 + n_transform)  # original + aumentadas\n",
    "    contador = 0\n",
    "    tiempo_inicio = time.time()\n",
    "    \n",
    "    for idx, (imagen, nombre_archivo) in enumerate(imagenes):\n",
    "        nombre_base = os.path.splitext(nombre_archivo)[0]\n",
    "        \n",
    "        # Guardar original\n",
    "        img_bgr = cv2.cvtColor(imagen, cv2.COLOR_RGB2BGR)\n",
    "        nombre_original = f\"{nombre_base}_original.jpg\"\n",
    "        cv2.imwrite(os.path.join(ruta_salida, nombre_original), img_bgr)\n",
    "        contador += 1\n",
    "        \n",
    "        # Mostrar progreso\n",
    "        tiempo_actual = time.time()\n",
    "        tiempo_transcurrido = tiempo_actual - tiempo_inicio\n",
    "        tiempo_promedio = tiempo_transcurrido / contador\n",
    "        tiempo_restante = tiempo_promedio * (total_imagenes - contador)\n",
    "        progreso_pct = (contador / total_imagenes) * 100\n",
    "        print(f\"\\rProcesando imagen {contador}/{total_imagenes} \"\n",
    "              f\"({progreso_pct:.2f}%) - Tiempo estimado restante: {tiempo_restante:.1f} seg\", end='')\n",
    "        \n",
    "        # Elegir aleatoriamente las transformaciones\n",
    "        datagens_seleccionados = random.sample(datagens, n_transform)\n",
    "        img_exp = np.expand_dims(imagen, 0)\n",
    "        \n",
    "        for i, datagen in enumerate(datagens_seleccionados):\n",
    "            it = datagen.flow(img_exp, batch_size=1)\n",
    "            imagen_aug = next(it)[0].astype(np.uint8)\n",
    "            imagen_aug_bgr = cv2.cvtColor(imagen_aug, cv2.COLOR_RGB2BGR)\n",
    "            nombre_nuevo = f\"{nombre_base}_aug{i}.jpg\"\n",
    "            cv2.imwrite(os.path.join(ruta_salida, nombre_nuevo), imagen_aug_bgr)\n",
    "            contador += 1\n",
    "            \n",
    "            # Actualizar progreso\n",
    "            tiempo_actual = time.time()\n",
    "            tiempo_transcurrido = tiempo_actual - tiempo_inicio\n",
    "            tiempo_promedio = tiempo_transcurrido / contador\n",
    "            tiempo_restante = tiempo_promedio * (total_imagenes - contador)\n",
    "            progreso_pct = (contador / total_imagenes) * 100\n",
    "            \n",
    "            print(f\"\\rProcesando imagen {contador}/{total_imagenes} \"\n",
    "                  f\"({progreso_pct:.2f}%) - Tiempo estimado restante: {tiempo_restante:.1f} seg\", end='')\n",
    "    print(\"\\n✅ Proceso terminado.\")\n",
    "\n",
    "# Rutas\n",
    "ruta_no_casco = r'C:\\Users\\Andres\\Desktop\\Data\\Newalldata\\Newdata\\No_casco'\n",
    "ruta_casco = r'C:\\Users\\Andres\\Desktop\\Data\\Newalldata\\Newdata\\Casco'\n",
    "ruta_salida_base = r'C:\\Users\\Andres\\Desktop\\Data\\Newalldata\\dataset_transformado'\n",
    "\n",
    "ruta_no_casco_salida = os.path.join(ruta_salida_base, 'No_casco')\n",
    "ruta_casco_salida = os.path.join(ruta_salida_base, 'Casco')\n",
    "\n",
    "# Cargar imágenes\n",
    "imagenes_no_casco = cargar_imagenes_cv2(ruta_no_casco)\n",
    "imagenes_casco = cargar_imagenes_cv2(ruta_casco)\n",
    "\n",
    "# Ejecutar\n",
    "guardar_imagenes_aumentadas(imagenes_no_casco, combinaciones_no_casco, ruta_no_casco_salida, n_transform=3)\n",
    "guardar_imagenes_aumentadas(imagenes_casco, combinaciones_casco, ruta_casco_salida, n_transform=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8046a2",
   "metadata": {},
   "source": [
    "# Redimencionar y cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe842a4-8d49-4166-a8d1-e5c868e1ccce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (31441, 128, 128, 3)\n",
      "Val: (6737, 128, 128, 3)\n",
      "Test: (6738, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TAMANO_IMG = 128\n",
    "\n",
    "# Usar ruta con doble backslash (\\\\) o con r\"\" crudo\n",
    "ruta_dataset = \"C:\\\\Users\\\\Andres\\\\Desktop\\\\Data\\\\Newalldata\\\\dataset_transformado\"  # Carpeta que contiene Casco y No_casco\n",
    "\n",
    "clases = {'No_casco': 0, 'Casco': 1}\n",
    "imagenes = []\n",
    "etiquetas = []\n",
    "\n",
    "# Cargar imágenes\n",
    "for clase, etiqueta in clases.items():\n",
    "    carpeta = os.path.join(ruta_dataset, clase)\n",
    "    if not os.path.isdir(carpeta):\n",
    "        print(f\"⚠️ Carpeta no encontrada: {carpeta}\")\n",
    "        continue\n",
    "\n",
    "    for archivo in os.listdir(carpeta):\n",
    "        ruta_imagen = os.path.join(carpeta, archivo)\n",
    "\n",
    "        try:\n",
    "            imagen = cv2.imread(ruta_imagen)\n",
    "            if imagen is None:\n",
    "                print(f\"❌ No se pudo leer la imagen: {ruta_imagen}\")\n",
    "                continue\n",
    "\n",
    "            imagen = cv2.resize(imagen, (TAMANO_IMG, TAMANO_IMG))\n",
    "            imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB)\n",
    "            imagenes.append(imagen)\n",
    "            etiquetas.append(etiqueta)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error con {ruta_imagen}: {e}\")\n",
    "\n",
    "# Convertir listas a arrays\n",
    "X = np.array(imagenes)\n",
    "y = np.array(etiquetas)\n",
    "\n",
    "# División de datos: 70% train, 15% val, 15% test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, stratify=y, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Val:\", X_val.shape)\n",
    "print(\"Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8be0653",
   "metadata": {},
   "source": [
    "# Normalizar datos de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d7c52b0-e6dd-4b2a-83f7-168fce463009",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "#X = np.array(X).astype(np.float32) / 255.0\n",
    "\n",
    "X_train = X_train.astype(np.float32) / 255.0\n",
    "X_val = X_val.astype(np.float32) / 255.0\n",
    "X_test = X_test.astype(np.float32) / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5fe1d31-d084-42ce-a562-8e4a4d4d811f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44916, 128, 128, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf528b-f019-4658-b473-ae20da5ab80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7d930383-1761-4602-abd0-068ed4c13e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andres\\miniconda3\\envs\\myenvironment\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Users\\Andres\\miniconda3\\envs\\myenvironment\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "modeloDenso = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(128, 128, 3)),\n",
    "  tf.keras.layers.Dense(150, activation='relu'),\n",
    "  tf.keras.layers.Dense(150, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "modeloCNN = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(100, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "modeloCNN2 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(250, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3d8165-b630-4597-8830-4a70330921ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilar modelos. Usar crossentropy binario ya que tenemos solo 2 opciones (perro o gato)\n",
    "modeloDenso.compile(optimizer='adam',\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "modeloCNN.compile(optimizer='adam',\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "modeloCNN2.compile(optimizer='adam',\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed7d97f-9854-4bd9-9713-97d35dca7d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.6770 - loss: 1.6816 - val_accuracy: 0.7392 - val_loss: 0.5155\n",
      "Epoch 2/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.7399 - loss: 0.5125 - val_accuracy: 0.7707 - val_loss: 0.4509\n",
      "Epoch 3/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.7566 - loss: 0.4751 - val_accuracy: 0.7922 - val_loss: 0.4192\n",
      "Epoch 4/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.7736 - loss: 0.4391 - val_accuracy: 0.7965 - val_loss: 0.4017\n",
      "Epoch 5/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.7834 - loss: 0.4228 - val_accuracy: 0.7811 - val_loss: 0.4162\n",
      "Epoch 6/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.7876 - loss: 0.4148 - val_accuracy: 0.7485 - val_loss: 0.4433\n",
      "Epoch 7/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.7973 - loss: 0.4119 - val_accuracy: 0.7626 - val_loss: 0.4490\n",
      "Epoch 8/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.7794 - loss: 0.4221 - val_accuracy: 0.7916 - val_loss: 0.4205\n",
      "Epoch 9/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.7854 - loss: 0.4086 - val_accuracy: 0.7522 - val_loss: 0.4595\n",
      "Epoch 10/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.7705 - loss: 0.4219 - val_accuracy: 0.7707 - val_loss: 0.4644\n",
      "Epoch 11/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.7899 - loss: 0.4090 - val_accuracy: 0.8021 - val_loss: 0.4206\n",
      "Epoch 12/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.7953 - loss: 0.4056 - val_accuracy: 0.7848 - val_loss: 0.4184\n",
      "Epoch 13/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.7925 - loss: 0.4098 - val_accuracy: 0.7700 - val_loss: 0.4374\n",
      "Epoch 14/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.8065 - loss: 0.3934 - val_accuracy: 0.7855 - val_loss: 0.4341\n",
      "Epoch 15/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.8148 - loss: 0.3808 - val_accuracy: 0.7848 - val_loss: 0.4503\n",
      "Epoch 16/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.8048 - loss: 0.3958 - val_accuracy: 0.7861 - val_loss: 0.4821\n",
      "Epoch 17/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.7948 - loss: 0.4148 - val_accuracy: 0.7922 - val_loss: 0.5300\n",
      "Epoch 18/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.8099 - loss: 0.3777 - val_accuracy: 0.7836 - val_loss: 0.4496\n",
      "Epoch 19/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.8126 - loss: 0.3788 - val_accuracy: 0.7682 - val_loss: 0.4720\n",
      "Epoch 20/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.8239 - loss: 0.3610 - val_accuracy: 0.8150 - val_loss: 0.4320\n",
      "Epoch 21/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.8274 - loss: 0.3540 - val_accuracy: 0.7010 - val_loss: 0.6429\n",
      "Epoch 22/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.8220 - loss: 0.3684 - val_accuracy: 0.8070 - val_loss: 0.4473\n",
      "Epoch 23/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.8274 - loss: 0.3613 - val_accuracy: 0.8107 - val_loss: 0.4146\n",
      "Epoch 24/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.8342 - loss: 0.3455 - val_accuracy: 0.8163 - val_loss: 0.4582\n",
      "Epoch 25/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.8446 - loss: 0.3367 - val_accuracy: 0.8274 - val_loss: 0.4423\n",
      "Epoch 26/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.8309 - loss: 0.3356 - val_accuracy: 0.8002 - val_loss: 0.4675\n",
      "Epoch 27/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.8510 - loss: 0.3284 - val_accuracy: 0.8169 - val_loss: 0.5650\n",
      "Epoch 28/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.8219 - loss: 0.3609 - val_accuracy: 0.7842 - val_loss: 0.4761\n",
      "Epoch 29/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.8473 - loss: 0.3437 - val_accuracy: 0.7885 - val_loss: 0.4648\n",
      "Epoch 30/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.8380 - loss: 0.3396 - val_accuracy: 0.8126 - val_loss: 0.4585\n",
      "Epoch 31/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.8438 - loss: 0.3287 - val_accuracy: 0.8200 - val_loss: 0.4908\n",
      "Epoch 32/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.8436 - loss: 0.3310 - val_accuracy: 0.8002 - val_loss: 0.5503\n",
      "Epoch 33/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.8403 - loss: 0.3389 - val_accuracy: 0.8157 - val_loss: 0.4510\n",
      "Epoch 34/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.8453 - loss: 0.3280 - val_accuracy: 0.8083 - val_loss: 0.4593\n",
      "Epoch 35/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.8609 - loss: 0.2940 - val_accuracy: 0.8089 - val_loss: 0.4513\n",
      "Epoch 36/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.8592 - loss: 0.3021 - val_accuracy: 0.7534 - val_loss: 0.5203\n",
      "Epoch 37/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.8486 - loss: 0.3251 - val_accuracy: 0.8157 - val_loss: 0.4673\n",
      "Epoch 38/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.8618 - loss: 0.2995 - val_accuracy: 0.8157 - val_loss: 0.5107\n",
      "Epoch 39/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.8673 - loss: 0.2909 - val_accuracy: 0.8076 - val_loss: 0.4702\n",
      "Epoch 40/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.8614 - loss: 0.2952 - val_accuracy: 0.8224 - val_loss: 0.4232\n",
      "Epoch 41/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.8559 - loss: 0.3028 - val_accuracy: 0.8163 - val_loss: 0.5709\n",
      "Epoch 42/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.8402 - loss: 0.3424 - val_accuracy: 0.8224 - val_loss: 0.4956\n",
      "Epoch 43/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.8818 - loss: 0.2653 - val_accuracy: 0.8206 - val_loss: 0.5161\n",
      "Epoch 44/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.8601 - loss: 0.2976 - val_accuracy: 0.7941 - val_loss: 0.5679\n",
      "Epoch 45/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.8534 - loss: 0.3227 - val_accuracy: 0.8194 - val_loss: 0.4997\n",
      "Epoch 46/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.8654 - loss: 0.2902 - val_accuracy: 0.8280 - val_loss: 0.4276\n",
      "Epoch 47/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.8671 - loss: 0.2838 - val_accuracy: 0.8126 - val_loss: 0.4684\n",
      "Epoch 48/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.8788 - loss: 0.2750 - val_accuracy: 0.8249 - val_loss: 0.5681\n",
      "Epoch 49/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.8705 - loss: 0.2769 - val_accuracy: 0.8113 - val_loss: 0.5052\n",
      "Epoch 50/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.8805 - loss: 0.2639 - val_accuracy: 0.7842 - val_loss: 0.5300\n",
      "Epoch 51/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.8601 - loss: 0.3130 - val_accuracy: 0.7978 - val_loss: 0.5282\n",
      "Epoch 52/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.8785 - loss: 0.2770 - val_accuracy: 0.8243 - val_loss: 0.5605\n",
      "Epoch 53/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.8864 - loss: 0.2581 - val_accuracy: 0.8083 - val_loss: 0.5041\n",
      "Epoch 54/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.8842 - loss: 0.2557 - val_accuracy: 0.7608 - val_loss: 0.7901\n",
      "Epoch 55/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.8641 - loss: 0.2940 - val_accuracy: 0.8138 - val_loss: 0.4798\n",
      "Epoch 56/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.8931 - loss: 0.2486 - val_accuracy: 0.8163 - val_loss: 0.5612\n",
      "Epoch 57/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.8769 - loss: 0.2691 - val_accuracy: 0.8083 - val_loss: 0.5572\n",
      "Epoch 58/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.8885 - loss: 0.2597 - val_accuracy: 0.8150 - val_loss: 0.6097\n",
      "Epoch 59/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.8854 - loss: 0.2650 - val_accuracy: 0.8194 - val_loss: 0.5104\n",
      "Epoch 60/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.8937 - loss: 0.2477 - val_accuracy: 0.8200 - val_loss: 0.4871\n",
      "Epoch 61/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.8929 - loss: 0.2461 - val_accuracy: 0.8187 - val_loss: 0.4999\n",
      "Epoch 62/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.8920 - loss: 0.2560 - val_accuracy: 0.7941 - val_loss: 0.5442\n",
      "Epoch 63/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.8801 - loss: 0.2656 - val_accuracy: 0.8138 - val_loss: 0.5143\n",
      "Epoch 64/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.8920 - loss: 0.2461 - val_accuracy: 0.8107 - val_loss: 0.4980\n",
      "Epoch 65/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.8907 - loss: 0.2447 - val_accuracy: 0.7959 - val_loss: 0.6059\n",
      "Epoch 66/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.8921 - loss: 0.2467 - val_accuracy: 0.8126 - val_loss: 0.5438\n",
      "Epoch 67/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.8890 - loss: 0.2508 - val_accuracy: 0.8150 - val_loss: 0.5091\n",
      "Epoch 68/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.8931 - loss: 0.2368 - val_accuracy: 0.7522 - val_loss: 0.4752\n",
      "Epoch 69/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.8698 - loss: 0.2787 - val_accuracy: 0.8163 - val_loss: 0.4679\n",
      "Epoch 70/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9010 - loss: 0.2257 - val_accuracy: 0.8138 - val_loss: 0.4718\n",
      "Epoch 71/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9004 - loss: 0.2281 - val_accuracy: 0.8126 - val_loss: 0.5729\n",
      "Epoch 72/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9019 - loss: 0.2221 - val_accuracy: 0.8218 - val_loss: 0.4405\n",
      "Epoch 73/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9131 - loss: 0.2070 - val_accuracy: 0.8169 - val_loss: 0.5041\n",
      "Epoch 74/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.8820 - loss: 0.2563 - val_accuracy: 0.8200 - val_loss: 0.5692\n",
      "Epoch 75/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9115 - loss: 0.2133 - val_accuracy: 0.7787 - val_loss: 0.5501\n",
      "Epoch 76/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.8822 - loss: 0.2591 - val_accuracy: 0.8095 - val_loss: 0.6409\n",
      "Epoch 77/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9065 - loss: 0.2177 - val_accuracy: 0.8107 - val_loss: 0.5553\n",
      "Epoch 78/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9105 - loss: 0.2061 - val_accuracy: 0.8126 - val_loss: 0.5341\n",
      "Epoch 79/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.9060 - loss: 0.2126 - val_accuracy: 0.7879 - val_loss: 0.6617\n",
      "Epoch 80/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.8745 - loss: 0.2623 - val_accuracy: 0.8231 - val_loss: 0.5449\n",
      "Epoch 81/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.9133 - loss: 0.2027 - val_accuracy: 0.8194 - val_loss: 0.6413\n",
      "Epoch 82/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.9046 - loss: 0.2131 - val_accuracy: 0.8163 - val_loss: 0.5508\n",
      "Epoch 83/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9071 - loss: 0.2170 - val_accuracy: 0.8231 - val_loss: 0.7409\n",
      "Epoch 84/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9109 - loss: 0.2065 - val_accuracy: 0.8206 - val_loss: 0.5496\n",
      "Epoch 85/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.9061 - loss: 0.2149 - val_accuracy: 0.8194 - val_loss: 0.5947\n",
      "Epoch 86/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.9071 - loss: 0.2096 - val_accuracy: 0.8163 - val_loss: 0.5828\n",
      "Epoch 87/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9163 - loss: 0.2035 - val_accuracy: 0.8052 - val_loss: 0.6821\n",
      "Epoch 88/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9140 - loss: 0.1992 - val_accuracy: 0.8163 - val_loss: 0.6912\n",
      "Epoch 89/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9037 - loss: 0.2351 - val_accuracy: 0.8243 - val_loss: 0.7350\n",
      "Epoch 90/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9124 - loss: 0.2090 - val_accuracy: 0.8194 - val_loss: 0.7036\n",
      "Epoch 91/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9010 - loss: 0.2287 - val_accuracy: 0.8076 - val_loss: 0.6508\n",
      "Epoch 92/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9131 - loss: 0.2031 - val_accuracy: 0.7787 - val_loss: 0.6885\n",
      "Epoch 93/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9069 - loss: 0.2267 - val_accuracy: 0.8076 - val_loss: 0.7275\n",
      "Epoch 94/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.9012 - loss: 0.2321 - val_accuracy: 0.8070 - val_loss: 0.6776\n",
      "Epoch 95/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.9063 - loss: 0.2103 - val_accuracy: 0.7978 - val_loss: 0.8503\n",
      "Epoch 96/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 60ms/step - accuracy: 0.9075 - loss: 0.2135 - val_accuracy: 0.7904 - val_loss: 0.7440\n",
      "Epoch 97/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9097 - loss: 0.2110 - val_accuracy: 0.8255 - val_loss: 0.9391\n",
      "Epoch 98/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9144 - loss: 0.1941 - val_accuracy: 0.8218 - val_loss: 0.8011\n",
      "Epoch 99/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9203 - loss: 0.1865 - val_accuracy: 0.8224 - val_loss: 0.6605\n",
      "Epoch 100/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9213 - loss: 0.1858 - val_accuracy: 0.8009 - val_loss: 0.6925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2952e071f00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "tensorboardDenso = TensorBoard(log_dir='logs/denso')\n",
    "modeloDenso.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[tensorboardDenso]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8818db3-8026-4667-ad87-ae02d282707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar la extension de tensorboard de colab\n",
    "%load_ext tensorboard\n",
    "#Ejecutar tensorboard e indicarle que lea la carpeta \"logs\"\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6512040-7ee5-42b2-8927-38495a8d6e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m 69/237\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 106ms/step - accuracy: 0.8738 - loss: 0.2788"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Para modeloCNN\u001b[39;00m\n\u001b[0;32m      4\u001b[0m tensorboardCNN \u001b[38;5;241m=\u001b[39m TensorBoard(log_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogs/cnn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodeloCNN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtensorboardCNN\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Andre\\anaconda3\\envs\\tf-env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Andre\\anaconda3\\envs\\tf-env\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\Andre\\anaconda3\\envs\\tf-env\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    219\u001b[0m     ):\n\u001b[1;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Andre\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Andre\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Andre\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Andre\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Andre\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Andre\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Andre\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Andre\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Andre\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "# Para modeloCNN\n",
    "tensorboardCNN = TensorBoard(log_dir='logs/cnn')\n",
    "modeloCNN.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[tensorboardCNN]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84453adb-6b85-458a-900b-8dbc84704f5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TensorBoard' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Para modeloCNN2\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tensorboardCNN2 \u001b[38;5;241m=\u001b[39m \u001b[43mTensorBoard\u001b[49m(log_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogs/cnn2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m modeloCNN2\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      4\u001b[0m     X_train, y_train,\n\u001b[0;32m      5\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[tensorboardCNN2]\n\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TensorBoard' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Para modeloCNN2\n",
    "tensorboardCNN2 = TensorBoard(log_dir='logs/cnn2')\n",
    "modeloCNN2.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[tensorboardCNN2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29a02834-b169-46ab-8dd7-963698ee2c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andres\\miniconda3\\envs\\tf-gpu-env\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "modeloCNN2_opt = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37dcc4ad-b83b-4a72-98f2-5ac77ae9a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloCNN2_opt.compile(optimizer='adam',\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea0aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 317ms/step - accuracy: 0.8375 - loss: 0.5845 - val_accuracy: 0.8841 - val_loss: 0.2890\n",
      "Epoch 2/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 312ms/step - accuracy: 0.9253 - loss: 0.1860 - val_accuracy: 0.8859 - val_loss: 0.2840\n",
      "Epoch 3/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 314ms/step - accuracy: 0.9520 - loss: 0.1307 - val_accuracy: 0.8140 - val_loss: 0.4885\n",
      "Epoch 4/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 310ms/step - accuracy: 0.9616 - loss: 0.1030 - val_accuracy: 0.9480 - val_loss: 0.1534\n",
      "Epoch 5/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 305ms/step - accuracy: 0.9701 - loss: 0.0784 - val_accuracy: 0.9633 - val_loss: 0.1030\n",
      "Epoch 6/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 302ms/step - accuracy: 0.9778 - loss: 0.0599 - val_accuracy: 0.9592 - val_loss: 0.1128\n",
      "Epoch 7/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 307ms/step - accuracy: 0.9789 - loss: 0.0602 - val_accuracy: 0.9575 - val_loss: 0.1693\n",
      "Epoch 8/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 316ms/step - accuracy: 0.9808 - loss: 0.0567 - val_accuracy: 0.9547 - val_loss: 0.1287\n",
      "Epoch 9/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 316ms/step - accuracy: 0.9862 - loss: 0.0440 - val_accuracy: 0.9121 - val_loss: 0.3036\n",
      "Epoch 10/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 314ms/step - accuracy: 0.9848 - loss: 0.0448 - val_accuracy: 0.9716 - val_loss: 0.0863\n",
      "Epoch 11/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 315ms/step - accuracy: 0.9857 - loss: 0.0392 - val_accuracy: 0.9696 - val_loss: 0.1260\n",
      "Epoch 12/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 329ms/step - accuracy: 0.9881 - loss: 0.0347 - val_accuracy: 0.9553 - val_loss: 0.1434\n",
      "Epoch 13/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 316ms/step - accuracy: 0.9886 - loss: 0.0367 - val_accuracy: 0.9739 - val_loss: 0.0865\n",
      "Epoch 14/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 316ms/step - accuracy: 0.9905 - loss: 0.0272 - val_accuracy: 0.9724 - val_loss: 0.0965\n",
      "Epoch 15/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 324ms/step - accuracy: 0.9895 - loss: 0.0333 - val_accuracy: 0.9641 - val_loss: 0.1459\n",
      "Epoch 16/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 325ms/step - accuracy: 0.9912 - loss: 0.0274 - val_accuracy: 0.9737 - val_loss: 0.1024\n",
      "Epoch 17/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 312ms/step - accuracy: 0.9897 - loss: 0.0362 - val_accuracy: 0.9454 - val_loss: 0.2432\n",
      "Epoch 18/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 314ms/step - accuracy: 0.9923 - loss: 0.0270 - val_accuracy: 0.9776 - val_loss: 0.0772\n",
      "Epoch 19/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 310ms/step - accuracy: 0.9923 - loss: 0.0252 - val_accuracy: 0.9834 - val_loss: 0.0638\n",
      "Epoch 20/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 315ms/step - accuracy: 0.9927 - loss: 0.0262 - val_accuracy: 0.9026 - val_loss: 0.8634\n",
      "Epoch 21/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 323ms/step - accuracy: 0.9927 - loss: 0.0239 - val_accuracy: 0.9780 - val_loss: 0.0731\n",
      "Epoch 22/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 315ms/step - accuracy: 0.9908 - loss: 0.0275 - val_accuracy: 0.9660 - val_loss: 0.1157\n",
      "Epoch 23/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 306ms/step - accuracy: 0.9921 - loss: 0.0313 - val_accuracy: 0.9524 - val_loss: 0.1605\n",
      "Epoch 24/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 307ms/step - accuracy: 0.9933 - loss: 0.0221 - val_accuracy: 0.9746 - val_loss: 0.1232\n",
      "Epoch 25/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 314ms/step - accuracy: 0.9939 - loss: 0.0212 - val_accuracy: 0.9823 - val_loss: 0.0927\n",
      "Epoch 26/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 325ms/step - accuracy: 0.9938 - loss: 0.0249 - val_accuracy: 0.9694 - val_loss: 0.1105\n",
      "Epoch 27/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 310ms/step - accuracy: 0.9929 - loss: 0.0219 - val_accuracy: 0.9645 - val_loss: 0.1165\n",
      "Epoch 28/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 312ms/step - accuracy: 0.9937 - loss: 0.0237 - val_accuracy: 0.9758 - val_loss: 0.1316\n",
      "Epoch 29/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 318ms/step - accuracy: 0.9944 - loss: 0.0182 - val_accuracy: 0.9789 - val_loss: 0.0761\n",
      "Epoch 30/100\n",
      "\u001b[1m764/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 310ms/step - accuracy: 0.9946 - loss: 0.0214"
     ]
    }
   ],
   "source": [
    "# Callback para monitorear con TensorBoard (opcional)\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir='logs/cnn2_opt')\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "modeloCNN2_opt.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[tensorboard],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5455d60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "#Cargar la extension de tensorboard de colab\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baadfc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2400), started 7:54:02 ago. (Use '!kill 2400' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-320ba6cd3c2ce84e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-320ba6cd3c2ce84e\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ejecutar tensorboard e indicarle que lea la carpeta \"logs\"\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa87a68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Guardar modelo completo\n",
    "modeloCNN2_opt.save(\"modeloCNN2_opt.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
